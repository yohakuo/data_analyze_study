import openai

# --- 1. é…ç½®æœ¬åœ° LLM æœåŠ¡å™¨ ---
# æœåŠ¡å™¨åœ°å€
LOCAL_BASE_URL = "http://192.168.121.57:11434/v1" 
# API å¯†é’¥å¯¹äºæœ¬åœ° Ollama æœåŠ¡æ¥è¯´ä¸æ˜¯å¿…éœ€çš„ï¼Œä½† openai åº“è¦æ±‚å¿…é¡»æä¾›ä¸€ä¸ªå€¼
LOCAL_API_KEY = "ollama" 
# æ¨¡å‹åç§°
MODEL_NAME = "qwen3:8b"


# --- 2. åˆ›å»ºä¸€ä¸ª OpenAI å®¢æˆ·ç«¯ï¼Œä½†è®©å®ƒæŒ‡å‘æˆ‘ä»¬çš„æœ¬åœ°æœåŠ¡å™¨ ---
try:
    client = openai.OpenAI(
        base_url=LOCAL_BASE_URL,
        api_key=LOCAL_API_KEY,
    )
    print("âœ… æˆåŠŸåˆ›å»º API å®¢æˆ·ç«¯ï¼Œå·²æŒ‡å‘æœ¬åœ°æœåŠ¡å™¨ã€‚")
except Exception as e:
    print(f"âŒ åˆ›å»º API å®¢æˆ·ç«¯å¤±è´¥: {e}")
    exit()


def list_available_models():
    """è·å–å¹¶æ‰“å°æœåŠ¡å™¨ä¸Šæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ã€‚"""
    print("\n--- æ­¥éª¤ 1: æ­£åœ¨è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨... ---")
    try:
        models = client.models.list()
        print("âœ… æˆåŠŸè·å–ï¼æœåŠ¡å™¨ä¸Šçš„å¯ç”¨æ¨¡å‹æœ‰ï¼š")
        for model in models.data:
            print(f"  - {model.id}")
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")


def chat_with_llm():
    """å‘æŒ‡å®šçš„ LLM å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤ã€‚"""
    print(f"\n--- æ­¥éª¤ 2: æ­£åœ¨å‘æ¨¡å‹ '{MODEL_NAME}' å‘é€æ¶ˆæ¯... ---")
    try:
        # è¿™æ˜¯æ ‡å‡†çš„ OpenAI å¯¹è¯ API è°ƒç”¨
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": "ä½ å¥½ï¼è¯·ç”¨ä¸­æ–‡ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
            ]
        )
        
        # ä»å›å¤ä¸­æå–å¹¶æ‰“å°å‡ºæ¨¡å‹çš„å›ç­”
        ai_message = response.choices[0].message.content
        print("\nğŸ¤– æ¨¡å‹å›å¤ï¼š")
        print(ai_message)
        
    except Exception as e:
        print(f"âŒ ä¸æ¨¡å‹å¯¹è¯å¤±è´¥: {e}")


if __name__ == "__main__":
    list_available_models()
    chat_with_llm()