import pandas as pd
import numpy as np
from zoneinfo import ZoneInfo
import datetime
import json
import time
import sys
import openai
from openai import OpenAI

# ä»æˆ‘ä»¬è‡ªå·±çš„æ¨¡å—ä¸­å¯¼å…¥æ‰€æœ‰å·¥å…·å’Œé…ç½®
from src import config
from src.dataset import get_timeseries_data
from src.features import calculate_hourly_features, recalculate_single_hour_features
from src.tools import TOOL_LIST

def find_canonical_field_name(user_term: str) -> str | None:
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥çš„è¯è¯­ï¼Œåœ¨ config çš„åˆ«åè¡¨ä¸­æŸ¥æ‰¾å¹¶è¿”å›è§„èŒƒçš„å­—æ®µåã€‚
    """
    # 1. å…ˆæ£€æŸ¥ç”¨æˆ·è¾“å…¥çš„è¯æœ¬èº«æ˜¯ä¸æ˜¯å°±æ˜¯ä¸€ä¸ªè§„èŒƒå
    if user_term in config.FIELD_ALIAS_MAP:
        return user_term
    
    # 2. éå†åˆ«åè¡¨ï¼ŒæŸ¥æ‰¾åŒ¹é…çš„åˆ«å
    for canonical_name, aliases in config.FIELD_ALIAS_MAP.items():
        if user_term in aliases:
            print(f"  [ç¿»è¯‘å®˜]ï¼šå·²å°†ç”¨æˆ·è¾“å…¥çš„ '{user_term}' ç¿»è¯‘ä¸ºè§„èŒƒå­—æ®µå '{canonical_name}'")
            return canonical_name
            
    # 3. å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å› None
    print(f"  [ç¿»è¯‘å®˜]ï¼šè­¦å‘Šï¼åœ¨åˆ«åè¡¨ä¸­æ‰¾ä¸åˆ°ä¸ '{user_term}' åŒ¹é…çš„å­—æ®µã€‚")
    return None

def create_local_llm_client():
    try:
        client = OpenAI(
            base_url="http://192.168.121.57:11434/v1",
            api_key="ollama"
        )
        print("âœ… æˆåŠŸåˆ›å»º API å®¢æˆ·ç«¯ï¼Œå·²æŒ‡å‘æœ¬åœ° Ollama æœåŠ¡ã€‚")
        return client
    except Exception as e:
        print(f"âŒ åˆ›å»º API å®¢æˆ·ç«¯å¤±è´¥: {e}")
        sys.exit(1)

def execute_tool_call(tool_call):
    """
    æ¥æ”¶ LLM è¿”å›çš„å·¥å…·è°ƒç”¨æŒ‡ä»¤ï¼Œå¹¶åœ¨ Python ä¸­æ‰§è¡Œå¯¹åº”çš„å‡½æ•°ã€‚
    """
    function_name = tool_call.function.name
    function_args = json.loads(tool_call.function.arguments)
    
    print(f"ğŸ¤– LLM å†³å®šè°ƒç”¨å‡½æ•°: {function_name}ï¼ŒåŸå§‹å‚æ•°: {function_args}")
    
    if function_name == "calculate_hourly_features":
        # a. ä» LLM çš„å‚æ•°ä¸­è·å–ç”¨æˆ·å¯èƒ½è¾“å…¥çš„å­—æ®µå
        user_field_name = function_args.get("field_name")
        
        # b. ===== å…³é”®ä¿®æ”¹ç‚¹ï¼šè®©â€œç¿»è¯‘å®˜â€ä¸Šå²—ï¼=====
        canonical_field_name = find_canonical_field_name(user_field_name)
        
        # c. å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œå°±æ— æ³•ç»§ç»­
        if not canonical_field_name:
            return {"error": f"æ— æ³•è¯†åˆ«çš„å­—æ®µå '{user_field_name}'ã€‚"}
            
        # d. ä½¿ç”¨ã€ç¿»è¯‘åã€‘çš„ã€è§„èŒƒçš„å­—æ®µåï¼Œæ‰§è¡Œåç»­æ‰€æœ‰æ“ä½œ
        features_to_calculate = function_args.get("features_to_calculate")
        start_time_str = function_args.get("start_time")
        end_time_str = function_args.get("end_time")

        local_tz = ZoneInfo(config.LOCAL_TIMEZONE)
        start_time_dt = datetime.datetime.strptime(start_time_str, "%Y-%m-%d").replace(tzinfo=local_tz) if start_time_str else None
        end_time_dt = datetime.datetime.strptime(end_time_str, "%Y-%m-%d").replace(tzinfo=local_tz) if end_time_str else None

        raw_df = get_timeseries_data(
            measurement_name=config.INFLUX_MEASUREMENT_NAME,
            field_name=canonical_field_name, # <-- ä½¿ç”¨è§„èŒƒå
            start_time=start_time_dt,
            stop_time=end_time_dt
        )

        features_df = calculate_hourly_features(raw_df, canonical_field_name, features_to_calculate) # <-- ä½¿ç”¨è§„èŒƒå
        
        return features_df.to_string(max_rows=5, max_cols=20)

    else:
        return {"error": "æœªæ‰¾åˆ°å¯¹åº”çš„å‡½æ•°"}

# --- 3. ä¸»å‡½æ•°ï¼šä»£ç†çš„äº¤äº’å¾ªç¯ ---
def main():
    client = create_local_llm_client()
    
    while True:
        user_message = input("\nè¯·æå‡ºä½ çš„æ•°æ®åˆ†æè¯·æ±‚ (è¾“å…¥ 'exit' é€€å‡º): ")
        if user_message.lower() == 'exit':
            break

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿå¤„ç†æ•°æ®åˆ†æä»»åŠ¡çš„å·¥å…·ä»£ç†ã€‚"},
            {"role": "user", "content": user_message}
        ]

        # æ ¸å¿ƒæ­¥éª¤ï¼šå°†ç”¨æˆ·è¯·æ±‚å’Œå·¥å…·ç®±æ¸…å•å‘ç»™ LLM
        response = client.chat.completions.create(
            model="qwen3:8b",
            messages=messages,
            tools=TOOL_LIST, # <-- è¿™é‡Œä¼ é€’äº†æˆ‘ä»¬çš„å·¥å…·ç®±æ¸…å•
            tool_choice="auto"
        )
        
        response_message = response.choices[0].message
        
        # æ£€æŸ¥ LLM æ˜¯å¦å†³å®šè°ƒç”¨å·¥å…·
        if response_message.tool_calls:
            tool_call = response_message.tool_calls[0]
            function_response = execute_tool_call(tool_call)
            
            # å°†å·¥å…·çš„æ‰§è¡Œç»“æœè¿”å›ç»™ LLM
            messages.append(response_message) # æ·»åŠ  LLM çš„å·¥å…·è°ƒç”¨æŒ‡ä»¤
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "name": tool_call.function.name,
                "content": function_response
            })
            
            # å†æ¬¡è°ƒç”¨ LLMï¼Œè®©å®ƒæ ¹æ®å·¥å…·çš„æ‰§è¡Œç»“æœè¿›è¡Œæ€»ç»“
            second_response = client.chat.completions.create(
                model="qwen3:8b",
                messages=messages
            )
            print("\nğŸ¤– æ¨¡å‹æ€»ç»“ï¼š")
            print(second_response.choices[0].message.content)

        else:
            print("\nğŸ¤– æ¨¡å‹å›å¤ï¼š")
            print(response_message.content)


if __name__ == "__main__":
    main()