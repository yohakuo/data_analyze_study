# ç‹¬ç«‹ï¼Œç›´æ¥ç»“æœ
import csv
from zoneinfo import ZoneInfo

import numpy as np
import pandas as pd
from src.validation import get_adjacent_feature_rows, get_raw_data_for_hour

# --- è¦éªŒè¯çš„ç›®æ ‡ ---
TABLE_TO_VALIDATE = "humidity_hourly_features_DongNan"
FIELD_TO_VALIDATE = "ç©ºæ°”æ¹¿åº¦ï¼ˆ%ï¼‰"


def calculate_percent_above_q3(series):
    """æ¥æ”¶ä¸€ä¸ªå°æ—¶çš„åŸå§‹æ•°æ®åºåˆ—(series)ï¼Œè®¡ç®—è¶…è¿‡Q3çš„æ•°æ®ç‚¹å æ¯”ã€‚"""
    if len(series) < 4:
        return 0.0
    q3 = series.quantile(0.75)
    if q3 == series.max():
        return 0.0
    count_above_q3 = (series > q3).sum()
    percent_above_q3 = count_above_q3 / len(series)
    return percent_above_q3


def recalculate_single_hour_features(
    raw_data_series: pd.Series, field_name: str
) -> pd.Series:
    """æ¥æ”¶ä¸€ä¸ªå°æ—¶çš„åŸå§‹æ•°æ®åºåˆ—ï¼Œé‡æ–°è®¡ç®—æ‰€æœ‰ç‰¹å¾å¹¶è¿”å›ä¸€ä¸ª Series"""
    if raw_data_series.empty:
        return pd.Series(dtype="object")

    # è®¡ç®—åŸºç¡€ç»Ÿè®¡ç‰¹å¾
    mean_val = raw_data_series.mean()
    median_val = raw_data_series.median()
    max_val = raw_data_series.max()
    min_val = raw_data_series.min()
    q1_val = raw_data_series.quantile(0.25)
    q3_val = raw_data_series.quantile(0.75)
    p10_val = raw_data_series.quantile(0.10)

    # è®¡ç®—è¡ç”Ÿç‰¹å¾
    range_val = max_val - min_val
    percent_above_q3_val = calculate_percent_above_q3(raw_data_series)

    # å°†ç»“æœæ‰“åŒ…æˆä¸€ä¸ª Series
    recalculated_features = pd.Series(
        {
            "å‡å€¼": mean_val,
            "ä¸­ä½æ•°_Q2": median_val,
            "æœ€å¤§å€¼": max_val,
            "æœ€å°å€¼": min_val,
            "Q1": q1_val,
            "Q3": q3_val,
            "P10": p10_val,
            "æå·®": range_val,
            "è¶…è¿‡Q3å æ—¶æ¯”": percent_above_q3_val,
        }
    )
    return recalculated_features


def main():
    pd.set_option("display.max_rows", None)
    LOCAL_TIMEZONE = ZoneInfo("Asia/Shanghai")

    standard_answers = get_adjacent_feature_rows(table_name=TABLE_TO_VALIDATE)

    if standard_answers is not None and len(standard_answers) == 2:
        previous_hour = standard_answers.iloc[0]
        current_hour = standard_answers.iloc[1]

        curr_time_local = (
            pd.to_datetime(current_hour["æ—¶é—´æ®µ"])
            .tz_localize("UTC")
            .tz_convert(LOCAL_TIMEZONE)
        )

        print(
            f"\n--- æ­£åœ¨éªŒè¯æ—¶é—´æ®µä¸º {curr_time_local.strftime('%Y-%m-%d %H:%M:%S')} çš„æ•°æ® ---"
        )

        timestamp_utc = pd.to_datetime(current_hour["æ—¶é—´æ®µ"]).tz_localize("UTC")
        raw_data_list = get_raw_data_for_hour(
            start_time_utc=timestamp_utc, field_name=FIELD_TO_VALIDATE
        )

        if not raw_data_list:
            print("âŒ é”™è¯¯ï¼šæœªèƒ½ä» InfluxDB è·å–åˆ°è¿™ä¸ªå°æ—¶çš„åŸå§‹æ•°æ®ï¼Œæ— æ³•è¿›è¡ŒéªŒè¯ã€‚")
            return

        # å°†åŸå§‹æ•°æ®åˆ—è¡¨è½¬æ¢ä¸º Seriesï¼Œä»¥ä¾¿æˆ‘ä»¬è¿›è¡Œè®¡ç®—
        raw_data_series = pd.Series(raw_data_list)

        # 1. é‡æ–°è®¡ç®—å½“å‰å°æ—¶çš„æ‰€æœ‰åŸºç¡€å’Œé«˜çº§ç‰¹å¾
        recalculated_features = recalculate_single_hour_features(
            raw_data_series, FIELD_TO_VALIDATE
        )

        # 2. å¯¹æ¯”ä¸¤ä¸ªç»“æœï¼Œå¹¶ç”ŸæˆæŠ¥å‘Š
        print("\n" + "=" * 60)
        print("         *** è‡ªåŠ¨åŒ–ç‰¹å¾éªŒè¯æŠ¥å‘Š ***")
        print("=" * 60)
        total_checks = 0
        failed_checks = 0

        # é€ä¸ªç‰¹å¾è¿›è¡Œå¯¹æ¯”
        for feature_name, recalculated_value in recalculated_features.items():
            stored_value = current_hour[feature_name]
            # ä½¿ç”¨ numpy çš„ isclose å‡½æ•°è¿›è¡Œæµ®ç‚¹æ•°æ¯”è¾ƒï¼Œæ›´å¯é 
            if np.isclose(recalculated_value, stored_value, atol=1e-5, rtol=1e-5):
                print(
                    f"âœ… {feature_name:<16}: è®¡ç®—å€¼={recalculated_value:8.4f}  |  å­˜å‚¨å€¼={stored_value:8.4f}  |  ç»“æœ: æ­£ç¡®"
                )
                total_checks += 1
            else:
                print(
                    f"âŒ {feature_name:<16}: è®¡ç®—å€¼={recalculated_value:8.4f}  |  å­˜å‚¨å€¼={stored_value:8.4f}  |  ç»“æœ: é”™è¯¯"
                )
                total_checks += 1
                failed_checks += 1

        # 3. éªŒè¯æœ€å¤æ‚çš„â€œæå·®çš„æ—¶é—´å˜åŒ–ç‡â€
        prev_range = previous_hour["æå·®"]
        curr_range = recalculated_features["æå·®"]

        manual_rate_of_change = 0.0
        if prev_range != 0:
            manual_rate_of_change = (curr_range - prev_range) / prev_range

        script_rate_of_change = current_hour["æå·®çš„æ—¶é—´å˜åŒ–ç‡"]

        print("\n" + "-" * 60)
        if np.isclose(manual_rate_of_change, script_rate_of_change, atol=1e-5):
            print(
                f"âœ… {'æå·®çš„æ—¶é—´å˜åŒ–ç‡':<22}: è®¡ç®—å€¼={manual_rate_of_change:8.4f}  |  å­˜å‚¨å€¼={script_rate_of_change:8.4f}  |  ç»“æœ: æ­£ç¡®"
            )
            total_checks += 1
        else:
            print(
                f"âŒ {'æå·®çš„æ—¶é—´å˜åŒ–ç‡':<22}: è®¡ç®—å€¼={manual_rate_of_change:8.4f}  |  å­˜å‚¨å€¼={script_rate_of_change:8.4f}  |  ç»“æœ: é”™è¯¯"
            )
            total_checks += 1
            failed_checks += 1

        print("=" * 60)
        if failed_checks == 0:
            print(f"ğŸ‰ æ­å–œï¼æ‰€æœ‰ {total_checks} é¡¹ç‰¹å¾éªŒè¯å…¨éƒ¨é€šè¿‡ï¼")
        else:
            print(f"âš ï¸ è­¦å‘Šï¼{failed_checks} é¡¹ç‰¹å¾éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ã€‚")
        print("=" * 60)

        # ä¸ºäº†æ–¹ä¾¿ä½ æŸ¥çœ‹ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç”ŸæˆåŸå§‹æ•°æ®çš„csv
        filename = f"validation_data_{curr_time_local.strftime('%Y-%m-%d_%H%M')}.csv"
        with open(filename, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow([FIELD_TO_VALIDATE])
            for value in raw_data_list:
                writer.writerow([value])
        print(f"\nâœ¨ åŸå§‹æ•°æ®å·²ä¿å­˜åˆ°æ–‡ä»¶: {filename}ï¼Œä¾¿äºæ‰‹åŠ¨å¤æŸ¥ã€‚")


if __name__ == "__main__":
    main()
