import datetime
import time
from zoneinfo import ZoneInfo

import clickhouse_connect
import pandas as pd
from influxdb_client import InfluxDBClient

# --- 1. InfluxDB è¿æ¥é…ç½® ---
INFLUXDB_URL = "http://localhost:8086"
INFLUXDB_TOKEN = "study2025"
INFLUXDB_ORG = "task3"
INFLUXDB_BUCKET = "cave45"

# # --- 2. æŸ¥è¯¢å‚æ•°é…ç½®  ---
# LOCAL_TIMEZONE = "Asia/Shanghai"
# START_YEAR = 2021
# START_MONTH = 1
# START_DAY = 1

# STOP_YEAR = 2021
# STOP_MONTH = 1
# STOP_DAY = 2 # æŸ¥è¯¢æˆªæ­¢åˆ° 1 æœˆ 2 æ—¥çš„ 0 ç‚¹ï¼Œæ­£å¥½æ˜¯ä¸€æ•´å¤©çš„æ•°æ®

MEASUREMENT_NAME = "adata"
FIELD_NAME = "ç©ºæ°”æ¹¿åº¦"

"""
ä» InfluxDB æŸ¥è¯¢å…¨éƒ¨æ¹¿åº¦æ•°æ®ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ¸…ç†å¥½çš„ Pandas DataFrame.
"""


def get_humidity_data() -> pd.DataFrame:
    with InfluxDBClient(
        url=INFLUXDB_URL, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG
    ) as client:
        # ä½¿ç”¨ range(start: 0) è·å–æ‰€æœ‰æ•°æ®
        query = f'''
        from(bucket: "{INFLUXDB_BUCKET}")
          |> range(start: 0)
          |> filter(fn: (r) => r["_measurement"] == "{MEASUREMENT_NAME}")
          |> filter(fn: (r) => r["_field"] == "{FIELD_NAME}")
          |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
        '''

        print("æ­£åœ¨ä» InfluxDB æŸ¥è¯¢ã€æ‰€æœ‰ã€‘æ•°æ®ï¼Œè¯·ç¨å€™...")
        df = client.query_api().query_data_frame(query=query, org=INFLUXDB_ORG)

        if df.empty:
            print("è­¦å‘Šï¼šæŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥ InfluxDB ä¸­æ˜¯å¦æœ‰æ•°æ®ã€‚")
            return df

        print("æ•°æ®æŸ¥è¯¢æˆåŠŸï¼Œæ­£åœ¨è¿›è¡Œé¢„å¤„ç†...")

        if FIELD_NAME in df.columns and "_time" in df.columns:
            df_cleaned = df[["_time", FIELD_NAME]]
            df_cleaned = df_cleaned.set_index("_time")
            df_cleaned.index = pd.to_datetime(df_cleaned.index)
            df_cleaned[FIELD_NAME] = pd.to_numeric(
                df_cleaned[FIELD_NAME], errors="coerce"
            )
            df_cleaned = df_cleaned.dropna()
            return df_cleaned
        else:
            print("é”™è¯¯ï¼šè¿”å›çš„æ•°æ®ä¸­ç¼ºå°‘ '_time' æˆ– 'ç©ºæ°”æ¹¿åº¦' åˆ—ã€‚")


"""
æ¥æ”¶ä¸€ä¸ªå°æ—¶çš„åŸå§‹æ•°æ®åºåˆ—(series)ï¼Œè®¡ç®—è¶…è¿‡Q3çš„æ•°æ®ç‚¹å æ¯”ã€‚
"""


def calculate_percent_above_q3(series):
    if len(series) < 4:
        return 0.0
    q3 = series.quantile(0.75)
    # é¿å… Q3 ç­‰äºæœ€å¤§å€¼æ—¶ï¼Œæ²¡æœ‰æ•°èƒ½å¤§äº Q3 çš„æƒ…å†µ
    if q3 == series.max():
        return 0.0
    count_above_q3 = (series > q3).sum()
    percent_above_q3 = count_above_q3 / len(series)
    return percent_above_q3


"""
æ¥æ”¶åŸå§‹æ•°æ® DataFrameï¼Œè®¡ç®—å°æ—¶çº§ç»Ÿè®¡ç‰¹å¾ï¼Œå¹¶è¿”å›ç»“æœ DataFrame.
"""


def calculate_hourly_features(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return pd.DataFrame()

    print("\nå¼€å§‹è®¡ç®—å°æ—¶çº§ç»Ÿè®¡ç‰¹å¾...")

    # 1. å…ˆè®¡ç®—åŸºç¡€ç‰¹å¾
    hourly_stats = df.resample("h").agg(
        å‡å€¼=("ç©ºæ°”æ¹¿åº¦", "mean"),
        ä¸­ä½æ•°=("ç©ºæ°”æ¹¿åº¦", "median"),
        æœ€å¤§å€¼=("ç©ºæ°”æ¹¿åº¦", "max"),
        æœ€å°å€¼=("ç©ºæ°”æ¹¿åº¦", "min"),
        Q1=("ç©ºæ°”æ¹¿åº¦", lambda x: x.quantile(0.25)),
        Q3=("ç©ºæ°”æ¹¿åº¦", lambda x: x.quantile(0.75)),
        P10=("ç©ºæ°”æ¹¿åº¦", lambda x: x.quantile(0.10)),
    )
    hourly_stats["æå·®"] = hourly_stats["æœ€å¤§å€¼"] - hourly_stats["æœ€å°å€¼"]

    # 2. è®¡ç®—é«˜çº§ç‰¹å¾ä¸€ï¼šâ€œè¶…è¿‡ Q3 çš„å æ—¶æ¯”â€
    # æˆ‘ä»¬å¯¹æŒ‰å°æ—¶åˆ†ç»„çš„æ•°æ®ï¼Œåº”ç”¨(apply)æˆ‘ä»¬çš„è‡ªå®šä¹‰å‡½æ•°
    percent_above_q3 = df["ç©ºæ°”æ¹¿åº¦"].resample("h").apply(calculate_percent_above_q3)
    # å°†è®¡ç®—ç»“æœåˆå¹¶åˆ°æˆ‘ä»¬çš„ç‰¹å¾è¡¨é‡Œ
    hourly_stats["è¶…è¿‡Q3å æ—¶æ¯”"] = percent_above_q3

    # 3. è®¡ç®—é«˜çº§ç‰¹å¾äºŒï¼šâ€œæå·®çš„æ—¶é—´å˜åŒ–ç‡â€
    # ä½¿ç”¨ .pct_change() è®¡ç®—ä¸ä¸Šä¸€è¡Œçš„å˜åŒ–ç‡ï¼Œå¹¶ç”¨ 0 å¡«å……ç¬¬ä¸€ä¸ªæ— æ³•è®¡ç®—çš„ NaN å€¼
    hourly_stats["æå·®çš„æ—¶é—´å˜åŒ–ç‡"] = hourly_stats["æå·®"].pct_change().fillna(0)

    # 4. æœ€åæ•´ç†ä¸€ä¸‹åˆ—å
    hourly_stats.rename(
        columns={"ä¸­ä½æ•°": "ä¸­ä½æ•° (Q2)", "P10": "10thç™¾åˆ†ä½æ•°"}, inplace=True
    )

    print("æ‰€æœ‰å°æ—¶çº§ç‰¹å¾è®¡ç®—å®Œæˆï¼")
    return hourly_stats


"""
å°†è®¡ç®—å¥½çš„ç‰¹å¾ DataFrame å­˜å‚¨åˆ° ClickHouse æ•°æ®åº“ä¸­ã€‚
"""


def store_features_to_clickhouse(df: pd.DataFrame):
    if df.empty:
        print("\nç‰¹å¾æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å­˜å‚¨ã€‚")
        return

    print("\nå¼€å§‹å°†ç‰¹å¾æ•°æ®å­˜å…¥ ClickHouse...")

    # --- ClickHouse è¿æ¥é…ç½® ---
    CLICKHOUSE_HOST = "localhost"
    CLICKHOUSE_PORT = 8123
    DATABASE_NAME = "feature_db"
    TABLE_NAME = "humidity_hourly_features"

    try:
        # 1. è¿æ¥åˆ° ClickHouse
        # client.command() ç”¨äºæ‰§è¡ŒéæŸ¥è¯¢ç±»çš„ SQL è¯­å¥
        client = clickhouse_connect.get_client(
            host=CLICKHOUSE_HOST,
            port=CLICKHOUSE_PORT,
            username="default",
            password="study2025",
        )
        # 2. åˆ›å»ºæ•°æ®åº“ (å¦‚æœä¸å­˜åœ¨çš„è¯)
        client.command(f"CREATE DATABASE IF NOT EXISTS {DATABASE_NAME}")

        # 3. å®šä¹‰å»ºè¡¨è¯­å¥
        # æˆ‘ä»¬éœ€è¦æ ¹æ® DataFrame çš„åˆ—æ¥ç²¾å¿ƒè®¾è®¡è¡¨çš„ç»“æ„
        create_table_query = f"""
        CREATE TABLE IF NOT EXISTS {DATABASE_NAME}.{TABLE_NAME}
        (
            `æ—¶é—´æ®µ` DateTime,
            `åˆ†æå‘¨æœŸ` String,
            `å‡å€¼` Float64,
            `ä¸­ä½æ•°_Q2` Float64,
            `æœ€å¤§å€¼` Float64,
            `æœ€å°å€¼` Float64,
            `Q1` Float64,
            `Q3` Float64,
            `P10` Float64,
            `æå·®` Float64,
            `è¶…è¿‡Q3å æ—¶æ¯”` Float64,
            `æå·®çš„æ—¶é—´å˜åŒ–ç‡` Float64
        )
        ENGINE = MergeTree()
        ORDER BY `æ—¶é—´æ®µ`
        """
        client.command(create_table_query)
        print(f"æ•°æ®åº“ '{DATABASE_NAME}' å’Œè¡¨ '{TABLE_NAME}' å·²å‡†å¤‡å°±ç»ªã€‚")
        # 4. å‡†å¤‡æ•°æ®ç”¨äºæ’å…¥
        # a. å¤åˆ¶ä¸€ä»½æ•°æ®ï¼Œé¿å…ä¿®æ”¹åŸå§‹çš„ DataFrame
        df_to_insert = df.copy()

        # b. æ·»åŠ ä½ æœ€åˆè¦æ±‚çš„æè¿°æ€§å­—æ®µ
        df_to_insert["åˆ†æå‘¨æœŸ"] = "hourly"

        # c. æŠŠç´¢å¼•ï¼ˆæ—¶é—´ï¼‰å˜å›æ™®é€šåˆ—ï¼Œå¹¶é‡å‘½åä»¥åŒ¹é…è¡¨ç»“æ„
        df_to_insert = df_to_insert.reset_index()
        df_to_insert.rename(
            columns={
                "_time": "æ—¶é—´æ®µ",
                "ä¸­ä½æ•° (Q2)": "ä¸­ä½æ•°_Q2",
                "10thç™¾åˆ†ä½æ•°": "P10",
            },
            inplace=True,
        )

        # d. ç¡®ä¿åˆ—çš„é¡ºåºå’Œç±»å‹ä¸è¡¨å®šä¹‰ä¸€è‡´
        final_columns = [
            "æ—¶é—´æ®µ",
            "åˆ†æå‘¨æœŸ",
            "å‡å€¼",
            "ä¸­ä½æ•°_Q2",
            "æœ€å¤§å€¼",
            "æœ€å°å€¼",
            "Q1",
            "Q3",
            "P10",
            "æå·®",
            "è¶…è¿‡Q3å æ—¶æ¯”",
            "æå·®çš„æ—¶é—´å˜åŒ–ç‡",
        ]
        df_to_insert = df_to_insert[final_columns]

        # 5. æ’å…¥æ•°æ®
        print(f"æ­£åœ¨æ’å…¥ {len(df_to_insert)} è¡Œæ•°æ®...")
        client.insert_df(f"{DATABASE_NAME}.{TABLE_NAME}", df_to_insert)

        print("æ•°æ®æˆåŠŸå­˜å…¥ ClickHouseï¼")

    except Exception as e:
        print(f"å­˜å…¥ ClickHouse æ—¶å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    # humidity_df = get_humidity_data()

    # if not humidity_df.empty:
    #     print("\næ•°æ®å‡†å¤‡å®Œæˆï¼é¢„è§ˆå‰5æ¡æ•°æ®ï¼š")
    #     print(humidity_df.head())

    #     print(f"\næˆåŠŸæå–äº† {len(humidity_df)} æ¡æ¹¿åº¦æ•°æ®ã€‚")
    #     print(f"æ•°æ®æ—¶é—´èŒƒå›´ä» {humidity_df.index.min()} åˆ° {humidity_df.index.max()}")

    #     hourly_features = calculate_hourly_features(humidity_df)

    #     if not hourly_features.empty:
    #         print("\n===== å°æ—¶çº§ç‰¹å¾è®¡ç®—ç»“æœé¢„è§ˆï¼š=====")
    #         # .head(24) å¯ä»¥æ˜¾ç¤ºç¬¬ä¸€å¤©çš„24ä¸ªå°æ—¶çš„ç»“æœ
    #         print(hourly_features.head(24))

    #         store_features_to_clickhouse(hourly_features)
    pipeline_start_time = time.perf_counter()
    print("===== æ•°æ®æå–ä¸å‡†å¤‡ =====")
    extraction_start_time = time.perf_counter()

    humidity_df = get_humidity_data()

    extraction_end_time = time.perf_counter()
    extraction_duration = extraction_end_time - extraction_start_time
    print(f"âœ… ä» InfluxDB æå–æ•°æ®è€—æ—¶: {extraction_duration:.2f} ç§’")

    if not humidity_df.empty:
        print(f"    (å…±æå–äº† {len(humidity_df)} æ¡åŸå§‹æ•°æ®)")
        print("\n===== ç‰¹å¾å·¥ç¨‹è®¡ç®— =====")
        features_start_time = time.perf_counter()

        hourly_features = calculate_hourly_features(humidity_df)

        features_end_time = time.perf_counter()
        features_duration = features_end_time - features_start_time
        print(f"è®¡ç®—å°æ—¶çº§ç‰¹å¾è€—æ—¶: {features_duration:.2f} ç§’")

        if not hourly_features.empty:
            print(f"    (å…±ç”Ÿæˆäº† {len(hourly_features)} æ¡å°æ—¶çº§ç‰¹å¾)")
            # print(hourly_features.head(3)) # å¦‚æœä¸æƒ³çœ‹é¢„è§ˆå¯ä»¥æ³¨é‡Šæ‰è¿™è¡Œ

            print("\n===== æ•°æ®å­˜å‚¨ =====")
            storage_start_time = time.perf_counter()

            store_features_to_clickhouse(hourly_features)

            storage_end_time = time.perf_counter()
            storage_duration = storage_end_time - storage_start_time
            print(f"âœ… å­˜å…¥ ClickHouse è€—æ—¶: {storage_duration:.2f} ç§’")

    # --- æ€»ç»“ ---
    pipeline_end_time = time.perf_counter()
    pipeline_duration = pipeline_end_time - pipeline_start_time
    print(
        f"\nğŸ‰ ** æ•°æ®å¤„ç†æµæ°´çº¿å…¨éƒ¨æ‰§è¡Œå®Œæ¯•ï¼æ€»è€—æ—¶: {pipeline_duration:.2f} ç§’ ** ğŸ‰"
    )
